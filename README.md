I have based my project on this paper : https://arxiv.org/pdf/1706.04599.

Confidence calibration in neural networks is crucial for the reliability of probability estimates they provide, which are supposed to reflect true likelihoods of correctness. This aspect of neural network performance is especially important in domains where decisions must be made under uncertainty, such as in autonomous systems or medical diagnosis applications. The original paper indicates that ResNet architectures, when tested on CIFAR-100, exhibit significant calibration errors. The best strategy for calibration was found to be temperature scaling throughout all experiments. Selective temperature scaling was introduced in this paper: https://arxiv.org/pdf/2212.12053 for calibration of semantic segmentation models. The paper showed that selective temperature scaling actually outperforms temperature scaling for semantic segmentation models.

This project evaluates the performance of ResNet18 and ResNet34 on CIFAR-100 using various post-training calibration methods, including histogram binning, temperature scaling, vector scaling, and matrix scaling. This project uses a split of 45,000 images for training and 5,000 for validation. The validation set is used to learn the parameters for calibration. My implementation of the mentioned methods have shown that vector/matrix scaling. My results show that vector scaling and matrix scaling, when combined with L2 regularization, can help to avoid overfit to the validation set — a common issue in the absence of regularization —but also potentially outperform the widely used temperature scaling method. Furthermore, I tested the applicability of selective temperature scaling which was originally proposed for segmentation tasks. The results also show that selective temperature scaling does not perform well compared to the other methods implemented.

Adapting ResNet for CIFAR-100
In this project, I adapted the ResNet18 and ResNet34 architectures specifically for CIFAR-100 by changing the initial convolution and pooling layers. CIFAR-100 images are relatively small, with dimensions of 32x32 pixels, in contrast to the larger ImageNet images that ResNet was originally designed to process. I replaced the standard 7x7 convolutional layer with a 3x3 layer and eliminated the max pooling step at the beginning of the network. This modification allows the network to preserve more spatial information in the early layers, which is needed for capturing the fine-grained details needed to differentiate among the 100 classes in CIFAR-100. By maintaining higher resolution at the start, the model can access more information. This enhanced my model accuracy significantly.
